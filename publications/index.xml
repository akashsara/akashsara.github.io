<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Publications on Akash Saravanan</title><link>https://akashsara.github.io/publications/</link><description>Recent content in Publications on Akash Saravanan</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 12 Mar 2023 03:17:06 -0600</lastBuildDate><atom:link href="https://akashsara.github.io/publications/index.xml" rel="self" type="application/rss+xml"/><item><title>Visualizing Characters and Evaluating their Balance in Competitive Video Games</title><link>https://akashsara.github.io/publications/msc-thesis/</link><pubDate>Sun, 12 Mar 2023 03:17:06 -0600</pubDate><guid>https://akashsara.github.io/publications/msc-thesis/</guid><description>Many competitive online video games release new characters on a regular basis. Designing these characters requires significant effort on several aspects including art, story, music, and game balance. Thus automating the design of these aspects offers value in saving human effort. This thesis offers two major contributions to the open problem of video game character generation.
Our first contribution is a novel methodology for representing pixel art. We introduce the Pixel VQ-VAE, an enhanced VQ-VAE model with two enhancements to improve performance on pixel art.</description></item><item><title>Beating Battleship: A Comprehensive Analysis</title><link>https://akashsara.github.io/publications/battleship/</link><pubDate>Sun, 27 Oct 2019 16:36:11 +0430</pubDate><guid>https://akashsara.github.io/publications/battleship/</guid><description>It aims to be a complete study on the strategy game of Battleship. I generated 1,000,000 different board positions to test algorithms on.
Currently experimenting with 4 broad algorithms:
Random Parity-based Probability-based (including Monte Carlo simulations) Reinforcement Learning. Each algorithm is further augmented with heuristics &amp;amp;randomness when applicable.
For an overview of the game itself and past approaches to solving it (and also the current best one), check out this Data Genetics blog.</description></item><item><title>Natural Language Generation using Generative Adversarial Networks</title><link>https://akashsara.github.io/publications/nlg-gan/</link><pubDate>Wed, 01 May 2019 16:36:11 +0430</pubDate><guid>https://akashsara.github.io/publications/nlg-gan/</guid><description>Performed a comparative study of existing text generation methodologies and established a baseline performance using different models. Each model was trained on:
”Alice in Wonderland” ”The Adventures of Sherlock Holmes” The models we utilized for training included:
Classic LSTM Networks. A Sequence-to-Sequence Model using LSTMs &amp;amp; GRUs. A Transformer with Attention. Developed a novel Generative Adversarial Network (GAN) using an LSTM generator and a fully connected discriminator.
While the network generated coherent sentences, sequence models and transformers retained the best performance</description></item></channel></rss>